{
 "cells": [
  {
   "cell_type": "code",
   "id": "4c462a21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T23:01:08.690553400Z",
     "start_time": "2026-02-05T23:01:08.374332700Z"
    }
   },
   "source": [
    "import sqlite3\n",
    "\n",
    "database = sqlite3.connect(r\"C:\\\\Users\\\\swavi\\\\Documents\\\\GitHub\\\\F1-Stop-Strategy\\\\Databases\\\\database.db\")\n",
    "cursor = database.cursor()\n",
    "driverIds = []\n",
    "year = 2025\n",
    "\n",
    "cursor.execute(\n",
    "\t\t\"\"\"SELECT raceID FROM Race WHERE year = ?\"\"\",\n",
    "\t\t\t\t(year,)\n",
    "\t\t\t\t\t)\n",
    "races = [r[0] for r in cursor.fetchall()]\n",
    "\n",
    "\n",
    "def getDrivers(raceId):\n",
    "\t\tcursor.execute(\n",
    "\t\t\t\"\"\"\n",
    "\t\t\tSELECT DISTINCT d.driverId, d.code\n",
    "\t\t\tFROM Driver d\n",
    "\t\t\tJOIN LAP l ON l.driverId = d.driverId\n",
    "\t\t\tWHERE l.raceId = ?\n",
    "\t\t\t\"\"\",\n",
    "\t\t\t(raceId,)\n",
    "\t\t)\n",
    "\t\tdrivers = cursor.fetchall()\n",
    "\t\treturn drivers\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "4dcef88a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T23:01:08.799925600Z",
     "start_time": "2026-02-05T23:01:08.692293600Z"
    }
   },
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.ioff()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "allLaps = []\n",
    "allDrivers = []\n",
    "\n",
    "columns = [\n",
    "    \"throttlePerc100\",\n",
    "    \"throttlePerc0\",\n",
    "    \"avCornerBrakeDistance\",\n",
    "    \"throttleOscillation\",\n",
    "    \"coastingPerc\",\n",
    "    \"brakeChanges\",\n",
    "    \"avSpeedCornerDiff\",\n",
    "    \"avApexThrottle\",\n",
    "]\n",
    "\n",
    "\n",
    "data = {col: [] for col in columns}"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "f5466ce9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T23:01:08.866558500Z",
     "start_time": "2026-02-05T23:01:08.799925600Z"
    }
   },
   "source": [
    "def collectingData(race, driverIds, driverCodes, averages):\n",
    "  rows = []\n",
    "\n",
    "  for driverId, driverCode in zip(driverIds, driverCodes):\n",
    "    cursor.execute(\n",
    "      \"\"\"SELECT lapId\n",
    "         FROM Lap \n",
    "         WHERE raceId = ? AND driverId = ? AND attacking = ? AND defending = ?\"\"\",\n",
    "      (race, driverId, 0, 0)\n",
    "    )\n",
    "\n",
    "    lapIds = [laps[0] for laps in cursor.fetchall()]\n",
    "    lapFeatures = []\n",
    "\n",
    "    for lapId in lapIds:\n",
    "      cursor.execute(\n",
    "        f\"\"\"SELECT {\",\".join(columns)}\n",
    "            FROM Features\n",
    "            WHERE lapId = ?\"\"\",\n",
    "        (lapId,)\n",
    "      )\n",
    "\n",
    "      row = cursor.fetchone()\n",
    "\n",
    "      if row is None:\n",
    "        continue\n",
    "      if all(feature is not None for feature in row):\n",
    "        lapFeatures.append(row)\n",
    "\n",
    "    lapFeatures = np.array(lapFeatures, dtype=float)\n",
    "    if lapFeatures.shape[0] == 0:\n",
    "      continue\n",
    "\n",
    "    if averages:\n",
    "      values = lapFeatures.mean(axis=0)\n",
    "      rows.append(\n",
    "        dict(zip(columns, values), driver=driverCode, raceId=race)\n",
    "      )\n",
    "    else:\n",
    "      rows.extend(\n",
    "          dict(zip(columns, row), driver=driverCode, raceId=race)\n",
    "          for row in lapFeatures)\n",
    "  return pd.DataFrame(rows)\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "208bd733",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T23:01:10.435062300Z",
     "start_time": "2026-02-05T23:01:08.870614900Z"
    }
   },
   "source": [
    "averages = False\n",
    "rows = []\n",
    "\n",
    "for race in races:\n",
    "\t\tdrivers = getDrivers(race)\n",
    "\t\tdriverIds = [row[0] for row in drivers]\n",
    "\t\tdriverCodes = [row[1] for row in drivers]\n",
    "\t\tdfRace = (collectingData(race,driverIds,driverCodes,averages))\n",
    "\t\trows.append(dfRace)\n",
    "\n",
    "df = pd.concat(rows, ignore_index=True)\n",
    "df[columns] = df.groupby(\"raceId\")[columns].transform(\n",
    "    lambda x: (x - x.mean()) / x.std()\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "aef523aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T23:01:12.557515900Z",
     "start_time": "2026-02-05T23:01:10.570952300Z"
    }
   },
   "source": [
    "from hdbscan import HDBSCAN\n",
    "\n",
    "features = columns  \n",
    "allLapsDF = df[features].copy()\n",
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(allLapsDF)\n",
    "pca = PCA(n_components=2)\n",
    "Xpca = pca.fit_transform(scaled)\n",
    "hdb = HDBSCAN(min_cluster_size=60, min_samples=30,\n",
    "                      cluster_selection_method='leaf', metric='euclidean',prediction_data=True)\n",
    "labels = hdb.fit_predict(Xpca)\n",
    "from sklearn.metrics import silhouette_score\n",
    "print(\"Silhouette score:\", silhouette_score(Xpca, labels))\n",
    "df = df.reset_index(drop=True) \n",
    "df[\"cluster\"] = labels\n",
    "clusterSummary = df.groupby(\"cluster\")[features].mean()\n",
    "clusterAssignment = pd.crosstab(df.driver, df.cluster)\n",
    "clusterAssignmentPercentage = (clusterAssignment.div(clusterAssignment.sum(axis=0),axis=1) *100).round(2)\n",
    "print(clusterAssignment)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score: -0.45239806240046315\n",
      "cluster   -1   0   1   2   3   4\n",
      "driver                          \n",
      "ALB      353   0   2   9   3  12\n",
      "ALO      342   0   3   8   2  10\n",
      "ANT      397   0   1  16   2  14\n",
      "BEA      398   3   0   3   0   1\n",
      "BOR      397   0   5   9   4  20\n",
      "COL      184   0   2   2   1   5\n",
      "DOO      151   0   0   4   2   9\n",
      "GAS      316   0   5  11   5  11\n",
      "HAD      379   0   7   4   8  18\n",
      "HAM      444  21   0   0   0   1\n",
      "HUL      384   0   9  11  13  18\n",
      "LAW      390   0   5   7   3  19\n",
      "LEC      451  26   0   0   0   0\n",
      "NOR      449   0   5  17   1  24\n",
      "OCO      427  22   0   0   0   0\n",
      "PIA      440   1   9  16   3  26\n",
      "RUS      428   1   1  13   3  10\n",
      "SAI      391   0   2   6   0   7\n",
      "STR      363   0   1   6   1   9\n",
      "TSU      386   0   4   9   3  14\n",
      "VER      439   0   3   6   7  24\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T23:01:13.992723200Z",
     "start_time": "2026-02-05T23:01:12.606583100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "features = columns\n",
    "allLapsDF = df[features].copy()\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(allLapsDF)\n",
    "\n",
    "# Reduce to behaviour space\n",
    "pca = PCA(n_components=2)\n",
    "Xpca = pca.fit_transform(scaled)\n",
    "\n",
    "# Cluster\n",
    "kmeans = KMeans(n_clusters=7, random_state=42, n_init=20)\n",
    "labels = kmeans.fit_predict(Xpca)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Silhouette score:\", silhouette_score(Xpca, labels))\n",
    "\n",
    "# Attach to data\n",
    "df = df.reset_index(drop=True)\n",
    "df[\"cluster\"] = labels\n",
    "\n",
    "# Interpret\n",
    "clusterSummary = df.groupby(\"cluster\")[features].mean()\n",
    "clusterAssignment = pd.crosstab(df.driver, df.cluster)\n",
    "clusterAssignmentPercentage = (\n",
    "        clusterAssignment.div(clusterAssignment.sum(axis=0), axis=1) * 100\n",
    ").round(2)\n",
    "\n",
    "print(clusterAssignment)"
   ],
   "id": "61bc8ff7c6501454",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score: 0.31965731978173967\n",
      "cluster    0    1    2    3    4    5    6\n",
      "driver                                    \n",
      "ALB       15   50   26  169    1   54   64\n",
      "ALO       29   53   26  132    0   58   67\n",
      "ANT       27   62   24  170    0   63   84\n",
      "BEA        0  192   77   76   12   25   23\n",
      "BOR      129    6    4   89    0   57  150\n",
      "COL       28   35   16   53    0   42   20\n",
      "DOO        7   18    9   72    0   32   28\n",
      "GAS       28   33   25  144    0   61   57\n",
      "HAD      131    4    3  106    0  113   59\n",
      "HAM        0   33   95    2  334    1    1\n",
      "HUL      106   24    7  115    0   63  120\n",
      "LAW      119    3    2  110    0  110   80\n",
      "LEC        1   36  136   11  293    0    0\n",
      "NOR       96   30    8  137    1   57  167\n",
      "OCO        0  159  139    5  144    1    1\n",
      "PIA       85   72    9  115    4   54  156\n",
      "RUS       39   81   30  163    1   75   67\n",
      "SAI       33  103   52   99    6   70   43\n",
      "STR      168   21    9   63    1   44   74\n",
      "TSU      108   15   12  105    0   87   89\n",
      "VER      127   11    9  137    0   90  105\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T23:01:15.346720500Z",
     "start_time": "2026-02-05T23:01:14.056738200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = Xpca\n",
    "y = df['driver']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "preds = rf.predict(X_test)\n",
    "\n",
    "print(\"Driver identification accuracy:\", accuracy_score(y_test, preds))"
   ],
   "id": "196ce39fa2020ce3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver identification accuracy: 0.12863849765258217\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T23:18:06.780588900Z",
     "start_time": "2026-02-05T23:18:00.682838200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "joblib.dump(scaler, \"models/scaler.pkl\")\n",
    "joblib.dump(pca, \"models/pca.pkl\")\n",
    "joblib.dump(kmeans, \"models/kmeans.pkl\")\n",
    "joblib.dump(rf, \"models/random_forest.pkl\")\n",
    "joblib.dump(clusterAssignmentPercentage, \"models/cluster_map.pkl\")\n",
    "joblib.dump(columns, \"models/columns.pkl\")\n",
    "\n",
    "results_bundle = {\n",
    "    \"df\": df,\n",
    "    \"clusterAssignment\": clusterAssignment,\n",
    "    \"clusterSummary\": clusterSummary,\n",
    "    \"clusterAssignmentPercentage\": clusterAssignmentPercentage,\n",
    "    \"Xpca\": Xpca,\n",
    "    \"y_test\": y_test,\n",
    "    \"preds\": preds,\n",
    "    \"scaler\": scaler,\n",
    "    \"pca\": pca,\n",
    "    \"kmeans\": kmeans,\n",
    "    \"rf\": rf,\n",
    "    \"columns\": columns,\n",
    "    \"labels\": labels\n",
    "}\n",
    "\n",
    "joblib.dump(results_bundle, \"models/results_bundle.pkl\")"
   ],
   "id": "7a40f36e22564238",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/results_bundle.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
